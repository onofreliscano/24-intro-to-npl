{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> data/raw, models, reports\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 01\n",
    "# ESTRUCTURA DEL PROYECTO\n",
    "# - Crea carpetas para dataset, modelos y reportes\n",
    "# - Mantiene el repo limpio y reproducible\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"reports\", exist_ok=True)\n",
    "\n",
    "print(\"OK -> data/raw, models, reports\")\n",
    "# Resultado esperado:\n",
    "# Carpetas creadas sin error\n",
    "# Interpretación:\n",
    "# Repo listo para trabajar ordenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> data/raw/url_spam.csv | exists: True\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 02\n",
    "# DESCARGA DEL DATASET (url_spam.csv)\n",
    "# - Descarga desde el link oficial\n",
    "# - Guarda en data/raw para uso local\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://breathecode.herokuapp.com/asset/internal-link?id=435&path=url_spam.csv\"\n",
    "out_path = \"data/raw/url_spam.csv\"\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    urllib.request.urlretrieve(url, out_path)\n",
    "\n",
    "print(\"OK ->\", out_path, \"| exists:\", os.path.exists(out_path))\n",
    "# Resultado esperado:\n",
    "# Archivo data/raw/url_spam.csv existe\n",
    "# Interpretación:\n",
    "# Dataset listo para cargar en pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2999, 2)\n",
      "Columns: ['url', 'is_spam']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.hvper.com/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://briefingday.com/fan</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  is_spam\n",
       "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
       "1                             https://www.hvper.com/     True\n",
       "2                 https://briefingday.com/m/v4n3i4f3     True\n",
       "3   https://briefingday.com/n/20200618/m#commentform    False\n",
       "4                        https://briefingday.com/fan     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dedup: (2369, 2)\n",
      "X column: url\n",
      "y column: is_spam\n",
      "y distribution:\n",
      " is_spam\n",
      "False    2125\n",
      "True      244\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 03\n",
    "# CARGA + INSPECCIÓN RÁPIDA\n",
    "# - Lee CSV con pandas\n",
    "# - Elimina duplicados\n",
    "# - Detecta columnas X (url) y y (label) de forma robusta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/raw/url_spam.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "display(df.head(5))\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "print(\"After dedup:\", df.shape)\n",
    "\n",
    "x_col = \"url\" if \"url\" in df.columns else df.columns[0]\n",
    "\n",
    "possible_y = [c for c in df.columns if c.lower() in {\"is_spam\", \"spam\", \"label\", \"target\", \"category\", \"class\"}]\n",
    "if not possible_y:\n",
    "    possible_y = [c for c in df.columns if c != x_col]\n",
    "y_col = possible_y[0]\n",
    "\n",
    "print(\"X column:\", x_col)\n",
    "print(\"y column:\", y_col)\n",
    "print(\"y distribution:\\n\", df[y_col].value_counts(dropna=False).head(10))\n",
    "# Resultado esperado:\n",
    "# Columnas detectadas + distribución de clases\n",
    "# Interpretación:\n",
    "# Confirmas feature (URL) y target (spam/no spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique y: [np.int64(0), np.int64(1)]\n",
      "Spam ratio: 0.103\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 04\n",
    "# NORMALIZACIÓN DEL TARGET A 0/1\n",
    "# - Acepta labels tipo True/False, spam/ham, 0/1\n",
    "# - Evita errores por formatos mixtos\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_y(y):\n",
    "    # comments: Convert labels to binary 0/1 robustly\n",
    "    s = pd.Series(y)\n",
    "\n",
    "    if s.dtype == bool:\n",
    "        return s.astype(int).values\n",
    "\n",
    "    if s.dtype == object:\n",
    "        s2 = s.astype(str).str.lower().str.strip()\n",
    "        return s2.apply(lambda v: 1 if v in {\"1\", \"true\", \"spam\", \"yes\"} else 0).astype(int).values\n",
    "\n",
    "    return pd.to_numeric(s, errors=\"coerce\").fillna(0).astype(int).clip(0, 1).values\n",
    "\n",
    "y = normalize_y(df[y_col].values)\n",
    "print(\"Unique y:\", sorted(set(y)))\n",
    "print(\"Spam ratio:\", round(y.mean(), 4))\n",
    "# Resultado esperado:\n",
    "# Unique y: [0, 1]\n",
    "# Interpretación:\n",
    "# Target listo para clasificación binaria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://briefingday.us8.list-manage.com/unsubscribe -> ['http', 'briefingday', 'us8', 'list', 'manage', 'com', 'unsubscribe']\n",
      "https://www.hvper.com/ -> ['http', 'www', 'hvper', 'com']\n",
      "https://briefingday.com/m/v4n3i4f3 -> ['http', 'briefingday', 'com', 'v4n3i4f3']\n",
      "https://briefingday.com/n/20200618/m#commentform -> ['http', 'briefingday', 'com', 'commentform']\n",
      "https://briefingday.com/fan -> ['http', 'briefingday', 'com', 'fan']\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 05\n",
    "# PREPROCESADO NLP PARA URLs (TOKENIZACIÓN)\n",
    "# - Parsea URL en partes (scheme, host, path, query)\n",
    "# - Tokeniza por separadores/puntuación\n",
    "# - Quita stopwords, números puros, tokens cortos\n",
    "# - Lematiza para normalizar tokens\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlsplit, unquote\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "def url_to_tokens(url: str) -> list:\n",
    "    # comments: Robust URL tokenization for NLP models\n",
    "    url = \"\" if pd.isna(url) else str(url)\n",
    "    url = unquote(url).strip().lower()\n",
    "\n",
    "    parts = urlsplit(url)\n",
    "    raw = \" \".join([parts.scheme, parts.netloc, parts.path, parts.query, parts.fragment])\n",
    "\n",
    "    tokens = re.split(r\"[^a-z0-9]+\", raw)\n",
    "    tokens = [t for t in tokens if t and len(t) >= 3]\n",
    "\n",
    "    cleaned = []\n",
    "    for t in tokens:\n",
    "        if t in STOP_WORDS:\n",
    "            continue\n",
    "        if t.isdigit():\n",
    "            continue\n",
    "        lemma = LEMMATIZER.lemmatize(t)\n",
    "        cleaned.append(lemma)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "# Sanity check rápido\n",
    "sample_urls = df[x_col].astype(str).head(5).tolist()\n",
    "for u in sample_urls:\n",
    "    print(u, \"->\", url_to_tokens(u)[:12])\n",
    "\n",
    "# Resultado esperado:\n",
    "# Listas de tokens para URLs ejemplo\n",
    "# Interpretación:\n",
    "# Convertiste URLs en señales textuales entrenables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1895 Test: 474\n",
      "Train spam ratio: 0.1029\n",
      "Test spam ratio: 0.1034\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 06\n",
    "# TRAIN/TEST SPLIT ESTRATIFICADO\n",
    "# - Separa train/test para medir generalización\n",
    "# - Mantiene proporción spam/no-spam\n",
    "# - random_state fijo para reproducibilidad\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_raw = df[x_col].astype(str).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_raw, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(X_train), \"Test:\", len(X_test))\n",
    "print(\"Train spam ratio:\", round(y_train.mean(), 4))\n",
    "print(\"Test spam ratio:\", round(y_test.mean(), 4))\n",
    "\n",
    "# Resultado esperado:\n",
    "# Ratios similares en train/test\n",
    "# Interpretación:\n",
    "# Evaluación más justa y replicable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> baseline trained\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 07\n",
    "# PIPELINE BASELINE: TF-IDF + SVM LINEAL\n",
    "# - TF-IDF convierte texto a números\n",
    "# - SVM lineal suele ser baseline fuerte en NLP\n",
    "# - Pipeline evita desalineación entre vectorizer y modelo\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "baseline = Pipeline(steps=[\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        tokenizer=url_to_tokens,\n",
    "        preprocessor=None,\n",
    "        lowercase=False,\n",
    "        token_pattern=None,  # comments: required when using custom tokenizer\n",
    "        max_features=8000,\n",
    "        min_df=2,\n",
    "        max_df=0.9,\n",
    "        ngram_range=(1, 2)\n",
    "    )),\n",
    "    (\"svm\", SVC(kernel=\"linear\", C=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "print(\"OK -> baseline trained\")\n",
    "\n",
    "# Resultado esperado:\n",
    "# Mensaje de entrenamiento OK\n",
    "# Interpretación:\n",
    "# Primer detector funcional listo para evaluar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9304\n",
      "Baseline Confusion Matrix:\n",
      " [[421   4]\n",
      " [ 29  20]]\n",
      "\n",
      "Baseline Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9356    0.9906    0.9623       425\n",
      "           1     0.8333    0.4082    0.5479        49\n",
      "\n",
      "    accuracy                         0.9304       474\n",
      "   macro avg     0.8844    0.6994    0.7551       474\n",
      "weighted avg     0.9250    0.9304    0.9195       474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 08\n",
    "# EVALUACIÓN DEL BASELINE\n",
    "# - Accuracy + Precision/Recall/F1\n",
    "# - Confusion matrix para ver FP/FN\n",
    "# - En spam, FN suele ser lo más costoso\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = baseline.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Baseline Accuracy:\", round(acc, 4))\n",
    "print(\"Baseline Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nBaseline Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Resultado esperado:\n",
    "# Métricas impresas + matriz\n",
    "# Interpretación:\n",
    "# Ves si el modelo deja pasar spam (FN) o bloquea buenos (FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best params: {'svm__C': 5, 'svm__gamma': 0.5, 'svm__kernel': 'rbf', 'tfidf__max_features': 6000, 'tfidf__ngram_range': (1, 1)}\n",
      "Best CV F1: 0.6408\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 09\n",
    "# OPTIMIZACIÓN CON GRID SEARCH (F1)\n",
    "# - Busca mejores hiperparámetros sin “adivinar”\n",
    "# - CV estratificado para robustez\n",
    "# - scoring F1 para balance precision/recall\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "param_grid = {\n",
    "    \"tfidf__max_features\": [6000, 8000, 12000],\n",
    "    \"tfidf__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"svm__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svm__C\": [0.5, 1, 2, 5],\n",
    "    \"svm__gamma\": [\"scale\", 0.5, 0.1]  # comments: used by rbf; ignored by linear\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=baseline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", round(grid.best_score_, 4))\n",
    "\n",
    "# Resultado esperado:\n",
    "# Best params + best CV F1\n",
    "# Interpretación:\n",
    "# Ajuste sistemático para mejor performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Accuracy: 0.9409\n",
      "Optimized Confusion Matrix:\n",
      " [[418   7]\n",
      " [ 21  28]]\n",
      "\n",
      "Optimized Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9522    0.9835    0.9676       425\n",
      "           1     0.8000    0.5714    0.6667        49\n",
      "\n",
      "    accuracy                         0.9409       474\n",
      "   macro avg     0.8761    0.7775    0.8171       474\n",
      "weighted avg     0.9364    0.9409    0.9365       474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 10\n",
    "# EVALUACIÓN DEL MEJOR MODELO EN TEST\n",
    "# - Evalúa el best_estimator_ en test\n",
    "# - Compara contra baseline con métricas claras\n",
    "# - Confirma mejora real (no solo CV)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "y_pred_opt = best_model.predict(X_test)\n",
    "\n",
    "acc_opt = accuracy_score(y_test, y_pred_opt)\n",
    "cm_opt = confusion_matrix(y_test, y_pred_opt)\n",
    "\n",
    "print(\"Optimized Accuracy:\", round(acc_opt, 4))\n",
    "print(\"Optimized Confusion Matrix:\\n\", cm_opt)\n",
    "print(\"\\nOptimized Report:\\n\", classification_report(y_test, y_pred_opt, digits=4))\n",
    "\n",
    "# Resultado esperado:\n",
    "# Métricas optimizadas impresas\n",
    "# Interpretación:\n",
    "# Modelo final validado en datos no vistos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> saved: models/url_spam_svm_tfidf_42.joblib\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 11\n",
    "# GUARDADO DEL MODELO (PIPELINE COMPLETO)\n",
    "# - Guarda TF-IDF + SVM juntos (evita bugs)\n",
    "# - Nombre descriptivo con seed\n",
    "# - Listo para reutilizar o desplegar\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "model_path = \"models/url_spam_svm_tfidf_42.joblib\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(\"OK -> saved:\", model_path)\n",
    "\n",
    "# Resultado esperado:\n",
    "# Archivo .joblib en models/\n",
    "# Interpretación:\n",
    "# Modelo portable y reutilizable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://secure-login.example.com/account/verify?ref=free', 1), ('https://www.wikipedia.org/wiki/Natural_language_processing', 0), ('http://cheap-prize-now.biz/win/iphone?click=1', 0)]\n"
     ]
    }
   ],
   "source": [
    "# BLOQUE 12\n",
    "# SMOKE TEST DE INFERENCIA (CARGA + PREDICCIÓN)\n",
    "# - Carga el modelo guardado\n",
    "# - Predice URLs nuevas\n",
    "# - Valida que funciona end-to-end\n",
    "\n",
    "loaded = joblib.load(\"models/url_spam_svm_tfidf_42.joblib\")\n",
    "\n",
    "demo_urls = [\n",
    "    \"https://secure-login.example.com/account/verify?ref=free\",\n",
    "    \"https://www.wikipedia.org/wiki/Natural_language_processing\",\n",
    "    \"http://cheap-prize-now.biz/win/iphone?click=1\"\n",
    "]\n",
    "\n",
    "preds = loaded.predict(demo_urls).tolist()\n",
    "print(list(zip(demo_urls, preds)))\n",
    "\n",
    "# Resultado esperado:\n",
    "# Lista (url, 0/1) sin errores\n",
    "# Interpretación:\n",
    "# Pipeline listo para uso real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
